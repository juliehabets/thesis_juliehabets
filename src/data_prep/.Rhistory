after:treatment,
cluster =  ~ {dma},
data = paidsearch)
tidy(reg_did_log, conf.int = TRUE)
reg_did_log <- feols(log(revenue) ~ after +
treatment +
after:treatment,
data = paidsearch)
tidy(reg_did_log, conf.int = TRUE)
reg_did_log <- feols(log(revenue) ~ after +
treatment +
after:treatment
|
dma,
data = paidsearch)
tidy(reg_did_log, se='cluster', conf.int = TRUE)
#SE were se = "iid", but if there are clusters, se = "cluster". If vcov = "iid", then the standard-errors are based on the assumption that the errors are all independent and generated with the same law (in particular, same variance). If vcov = "hetero", this corresponds to the classic hereoskedasticity-robust standard-errors (White correction), where it is assumed that the errors are independent but the variance of their generative law may vary. If vcov = "cluster", then arbitrary correlation of the errors within clusters is accounted for. Same for vcov = "twoway": arbitrary correlation within each of the two clusters is accounted for.
reg_did_log_clust <- feols(log(revenue) ~ after +
treatment +
after:treatment,
cluster =  ~ {dma},
data = paidsearch)
tidy(reg_did_log, conf.int = TRUE)
reg_did_log <- feols(log(revenue) ~ after +
treatment +
after:treatment,
data = paidsearch)
tidy(reg_did_log, conf.int = TRUE)
reg_did <- feols(revenue ~ after +
treatment +
after:treatment,
data = paidsearch)
tidy(reg_did, conf.int = TRUE)
reg_did_log_fixed <- feols(log(revenue) ~ after +
treatment +
after:treatment
|
dma,
data = paidsearch)
tidy(reg_did_log, se='cluster', conf.int = TRUE)
reg_did_log_fixed <- feols(log(revenue) ~ after +
treatment +
after:treatment
|
dma,
data = paidsearch)
tidy(reg_did_log_fixed, se='cluster', conf.int = TRUE)
#SE were se = "iid", but if there are clusters, se = "cluster". If vcov = "iid", then the standard-errors are based on the assumption that the errors are all independent and generated with the same law (in particular, same variance). If vcov = "hetero", this corresponds to the classic hereoskedasticity-robust standard-errors (White correction), where it is assumed that the errors are independent but the variance of their generative law may vary. If vcov = "cluster", then arbitrary correlation of the errors within clusters is accounted for. Same for vcov = "twoway": arbitrary correlation within each of the two clusters is accounted for.
reg_did_log_clust <- feols(log(revenue) ~ after +
treatment +
after:treatment,
cluster =  ~ {dma},
data = paidsearch)
tidy(reg_did_log_clust, conf.int = TRUE)
reg_did_log_fixed <- feols(log(revenue) ~ after +
treatment +
after:treatment
|
dma,
data = paidsearch)
tidy(reg_did_log_fixed, se='cluster', conf.int = TRUE)
mods <- list(
reg_did,
reg_did_log,
reg_did_log_clust,
reg_did_log_fixed)
summary(mods,
coef_omit = "Interc",
gof_omit = "AIC|BIC|Log|Pseudo|F")
mods <- list(
reg_did,
reg_did_log,
reg_did_log_clust,
reg_did_log_fixed)
msummary(mods,
coef_omit = "Interc",
gof_omit = "AIC|BIC|Log|Pseudo|F")
library(arm)
install.packages("arm")
library(arm)
library(arm)
coefplot(mods)
library(arm)
coefplot(reg_did, reg_did_log, reg_did_log_clust, reg_did_log_fixed)
library(fixest)
coefplot(reg_did, reg_did_log, reg_did_log_clust, reg_did_log_fixed)
coefplot(reg_did)
?coefplot
library(fixest)
coefplot(mods)
url <- "https://raw.githubusercontent.com/TaddyLab/BDS/master/examples/paidsearch.csv"
# where to save data
out_file <- "data/paid_search.csv"
# download it!
download.file(url, destfile = out_file, mode = "wb")
library(readr)
library(dplyr)
library(tidyr)
library(lubridate)
library(fixest)
library(broom)
library(ggplot2)
library(modelsummary)
paidsearch <- read_csv("data/paid_search.csv")
spec(paidsearch)
library(janitor)
paidsearch <-
paidsearch %>%
clean_names()
paidsearch <-
paidsearch %>%
mutate(revenue = revenue/1000)
paidsearch <-
paidsearch %>%
mutate(date  = as_date(date, format = '%d-%b-%y'))
paidsearch %>%
group_by(date) %>%
summarise(revenue = mean(revenue)) %>%
ggplot(aes(x = date,
y = revenue)
) +
geom_line() +
scale_x_date(date_labels = "%Y %b %d") +
theme_bw()
paidsearch <-
paidsearch %>%
mutate(calweek = week(date))
grp_avg <-
paidsearch %>%
group_by(search_stays_on, calweek) %>%
summarise(revenue = mean(revenue)) %>%
arrange(calweek, search_stays_on)
knitr::include_graphics('figs/ebay_experiment.png')
exp_start <- as_date("2015-05-22")
grp_avg %>%
ggplot(aes(x = calweek,
y = revenue,
color = factor(search_stays_on)
)
) +
geom_line() +
geom_vline(xintercept = week(exp_start)) +
ggtitle("Average Daily Revenue from Search Engine Marketing") +
xlab("Calendar Week") +
ylab("Revenue ('000s of USD)") +
theme_bw()
paidsearch <-
paidsearch %>%
mutate(treatment = case_when(
search_stays_on == 0 ~ 1,
TRUE ~ 0
)
) %>%
rename(after = treatment_period)
treat_table <-
paidsearch %>%
group_by(after, treatment) %>%
summarise(revenue = mean(revenue)) %>%
ungroup()
print(treat_table)
diff_no_treat <- abs(128.0709	- 131.5569)
diff_treat <- 104.9987	- 100.4183
did <- diff_no_treat - diff_treat
reg_did <- feols(revenue ~ after +
treatment +
after:treatment,
data = paidsearch)
tidy(reg_did, conf.int = TRUE)
reg_did_log <- feols(log(revenue) ~ after +
treatment +
after:treatment,
data = paidsearch)
tidy(reg_did_log, conf.int = TRUE)
#SE were se = "iid", but if there are clusters, se = "cluster". If vcov = "iid", then the standard-errors are based on the assumption that the errors are all independent and generated with the same law (in particular, same variance). If vcov = "hetero", this corresponds to the classic hereoskedasticity-robust standard-errors (White correction), where it is assumed that the errors are independent but the variance of their generative law may vary. If vcov = "cluster", then arbitrary correlation of the errors within clusters is accounted for. Same for vcov = "twoway": arbitrary correlation within each of the two clusters is accounted for.
reg_did_log_clust <- feols(log(revenue) ~ after +
treatment +
after:treatment,
cluster =  ~ {dma},
data = paidsearch)
tidy(reg_did_log_clust, conf.int = TRUE)
reg_did_log_fixed <- feols(log(revenue) ~ after +
treatment +
after:treatment
|
dma,
data = paidsearch)
tidy(reg_did_log_fixed, se='cluster', conf.int = TRUE)
mods <- list(
reg_did,
reg_did_log,
reg_did_log_clust,
reg_did_log_fixed)
msummary(mods,
coef_omit = "Interc",
gof_omit = "AIC|BIC|Log|Pseudo|F")
library(fixest)
coefplot(mods)
# Write your answer here
grp_avg %>%
filter(calweek <= week(exp_start)) %>%
ggplot(aes(x = calweek,
y = revenue,
color = factor(search_stays_on)
)
) +
geom_line() +
ggtitle("Average Daily Revenue from Search Engine Marketing",
subtitle = "Pre-treatment Period") +
xlab("Calendar Week") +
ylab("Revenue ('000s of USD)") +
theme_bw()
install.packages("spotifyr")
library(spotifyr)
install.packages("vagalumeR")
library(vagalumeR)
# vagalumeR
artist <-"belle-sebastian"
song <- songNames(artist)
View(song)
library(tidyverse)
glimpse(lyrics_data)
lyrics_data <- song %>%
pull(song.id) %>%
purrr::map(lyrics,
artist = artist,
type = "id",
key = key) %>%
purrr::map_df(data.frame) %>%
slice(-15) # There is a repeated lyric there!
lyrics_data <- song %>%
pull(song.id) %>%
purrr::map(lyrics,
artist = artist,
type = "id",
key = key) %>%
purrr::map_df(data.frame) %>%
slice(-15) # There is a repeated lyric there!
# vagalumeR
key <- 835426a514b5ad77b79de934a7b936df
# vagalumeR
key <- "835426a514b5ad77b79de934a7b936df"
lyrics_data <- song %>%
pull(song.id) %>%
purrr::map(lyrics,
artist = artist,
type = "id",
key = key) %>%
purrr::map_df(data.frame) %>%
slice(-15) # There is a repeated lyric there!
glimpse(lyrics_data)
install.packages("Rspotify")
library(Rspotify)
install.packages("httr")
install.packages("httr")
library(httr)
library(Rspotify)
# Rspotify
my_oauth <- spotifyOAuth()
# Rspotify
my_oauth <- spotifyOAuth(client_id = "b57bb630866045ee85b513376a7f8cc5", client_secret = "391b897e9e204c27aaa35d7d7ba91c52")
# Rspotify
my_oauth <- spotifyOAuth(app_id = "thesis", client_id = "b57bb630866045ee85b513376a7f8cc5", client_secret = "391b897e9e204c27aaa35d7d7ba91c52")
library(Rspotify)
library(vagalumeR)
library(tidyverse)
library(httr)
# Rspotify
SPOTIFY_ID <- "b57bb630866045ee85b513376a7f8cc5"
SECRET_KEY <- "391b897e9e204c27aaa35d7d7ba91c52"
response <- POST(
"https://accounts.spotify.com/api/token",
config = authenticate(user = Sys.getenv("SPOTIFY_ID"),
password = Sys.getenv("SECRET_KEY")),
body = list(grant_type = "client_credentials"),
encode = "form"
)
#extract content of response
token <-  content(response)
# Paste the token_type with the access_token
# needs it when making the authorization
bearer.token <- paste(token$token_type, token$access_token)
track.id <- "5u6y4u5EgDv0peILf60H5t"
track.response <- GET(paste0("https://api.spotify.com/v1/audio-features/",track.id),
config = add_headers(Authorization = bearer.token)
)
View(track.response)
View(track.response)
library(dplyr)
# Paste the token_type with the access_token
# needs it when making the authorization
bearer.token <- paste(token$token_type, token$access_token)
track.response <- GET(paste0("https://api.spotify.com/v1/audio-features/",track.id),
config = add_headers(Authorization = bearer.token)
)
View(track.response)
track <- as_tibble(content( track.response ))
track.features <- track %>% select(c(1:11, 17, 18))
View(track)
View(response)
my_oauth <- spotifyOAuth(app_id = "thesis", client_id = "b57bb630866045ee85b513376a7f8cc5", client_secret = "391b897e9e204c27aaa35d7d7ba91c52")
)
my_oauth <- spotifyOAuth(app_id = "thesis", client_id = "b57bb630866045ee85b513376a7f8cc5", client_secret = "4db6865daf1f451fb3bc73b577e293b2")
my_oauth <- spotifyOAuth(app_id = "thesis", client_id = "b57bb630866045ee85b513376a7f8cc5", client_secret = "4db6865daf1f451fb3bc73b577e293b2")
my_oauth <- spotifyOAuth(app_id = "thesis", client_id = "b57bb630866045ee85b513376a7f8cc5", client_secret = "4db6865daf1f451fb3bc73b577e293b2")
my_oauth <- spotifyOAuth(app_id = "thesis", client_id = "b57bb630866045ee85b513376a7f8cc5", client_secret = "4db6865daf1f451fb3bc73b577e293b2")
install.packages("installr")
?installr
installing/loading the package: if(!require(installr)) { install.packages("installr"); require(installr)} #load / install+load installr   updateR(F, T, T, F, T, F, T) # install, move, update.package, quit R.
if(!require(installr)) { install.packages("installr"); require(installr)} #load / install+load installr   updateR(F, T, T, F, T, F, T) # install, move, update.package, quit R.
library(installr)
installing/loading the package: if(!require(installr)) { install.packages("installr"); require(installr)} #load / install+load installr   updateR(F, T, T, F, T, F, T) # install, move, update.package, quit R.
iif(!require(installr)) { install.packages("installr"); require(installr)} #load / install+load installr   updateR(F, T, T, F, T, F, T) # install, move, update.package, quit R.
if(!require(installr)) { install.packages("installr"); require(installr)} #load / install+load installr   updateR(F, T, T, F, T, F, T) # install, move, update.package, quit R.
if(!require(installr)) {
install.packages("installr"); require(installr)}
updateR()
updateR()
library(rtweet)
tweets <-
search_tweets(
"Spotify" + "Gender",
n = 400)
tweets <-
search_tweets(
c("Spotify", "Gender"),
n = 400)
tweets <-
search_tweets(
c("Spotify AND Gender"),
n = 400)
View(tweets)
tweets <-
search_tweets(
c("Spotify AND Gender"),
n = 400,
lang = 'en')
View(tweets)
tweets <-
search_tweets(
c("Spotify AND LGBTQ"),
n = 400,
lang = 'en')
View(tweets)
tweets <-
search_tweets(
"Spotify AND LGBTQ",
n = 400,
lang = 'en')
View(tweets)
tweets <-
search_tweets(
"Spotify AND LGBTQ",
n = 400,
lang = 'en',
include_rts = FALSE)
View(tweets)
tweets <-
search_tweets(
"Spotify AND Gender bias",
n = 400,
lang = 'en',
include_rts = FALSE)
tweets <-
search_tweets(
"Spotify AND genderbias",
n = 400,
lang = 'en',
include_rts = FALSE)
tweets <-
search_tweets(
"Spotify AND Bias",
n = 400,
lang = 'en',
include_rts = FALSE)
View(tweets)
tweets <-
search_tweets(
"Spotify AND gender AND bias",
n = 400,
lang = 'en',
include_rts = FALSE)
tweets <-
search_tweets(
"Spotify AND #blackhistorymonth",
n = 400,
lang = 'en',
include_rts = FALSE)
tweets <-
search_tweets(
"Spotify AND LGBTQ",
n = 400,
lang = 'en',
include_rts = FALSE)
View(tweets)
deezer <- search_tweets(
"Deezer",
n = 50,
lan = 'en'
)
library(rtweet)
deezer <- search_tweets(
"Deezer",
n = 50,
lan = 'en'
)
View(deezer)
?search_tweets
deezer <- search_tweets(
"Deezer",
n = 50,
lang = 'en'
)
View(deezer)
deezer <- search_tweets(
"#Deezer",
n = 50,
lang = 'en'
)
View(deezer)
library(readr)
install.packages("readr")
install.packages("readr")
library(installr)
install.packages("installr")
library(installr)
updateR()
library(readr)
install.packages("readr")
library(dplyr)
install.packages("dplyr")
install.packages("tidyverse")
install.packages("tidyverse")
# Load packages
library(tidyverse)
#Create data folder
dir.create("../../data")
# Input
urls_calender = c("http://data.insideairbnb.com/united-states/co/denver/2022-09-26/data/calendar.csv.gz",
"http://data.insideairbnb.com/ireland/leinster/dublin/2022-09-11/data/calendar.csv.gz",
"http://data.insideairbnb.com/united-kingdom/england/london/2022-09-10/data/calendar.csv.gz",
"http://data.insideairbnb.com/united-states/ca/los-angeles/2022-09-09/data/calendar.csv.gz",
"http://data.insideairbnb.com/italy/lombardy/milan/2022-09-14/data/calendar.csv.gz",
"http://data.insideairbnb.com/germany/bv/munich/2022-06-21/data/calendar.csv.gz",
"http://data.insideairbnb.com/united-states/ny/new-york-city/2022-09-07/data/calendar.csv.gz",
"http://data.insideairbnb.com/france/ile-de-france/paris/2022-06-06/data/calendar.csv.gz",
"http://data.insideairbnb.com/united-states/or/portland/2022-09-16/data/calendar.csv.gz",
"http://data.insideairbnb.com/united-states/ca/san-francisco/2022-09-07/data/calendar.csv.gz")
urls_listing = c("http://data.insideairbnb.com/united-states/co/denver/2022-09-26/data/listings.csv.gz",
"http://data.insideairbnb.com/ireland/leinster/dublin/2022-09-11/data/listings.csv.gz",
"http://data.insideairbnb.com/united-kingdom/england/london/2022-09-10/data/listings.csv.gz",
"http://data.insideairbnb.com/united-states/ca/los-angeles/2022-09-09/data/listings.csv.gz",
"http://data.insideairbnb.com/italy/lombardy/milan/2022-09-14/data/listings.csv.gz",
"http://data.insideairbnb.com/germany/bv/munich/2022-06-21/data/listings.csv.gz",
"http://data.insideairbnb.com/united-states/ny/new-york-city/2022-09-07/data/listings.csv.gz",
"http://data.insideairbnb.com/france/ile-de-france/paris/2022-06-06/data/listings.csv.gz",
"http://data.insideairbnb.com/united-states/or/portland/2022-09-16/data/listings.csv.gz",
"http://data.insideairbnb.com/united-states/ca/san-francisco/2022-09-07/data/listings.csv.gz")
install.packages("readr")
install.packages("readr")
install.packages("data.table")
install.packages("shiny")
install.packages("shinyWidgets")
install.packages("bslib")
install.packages("shinythemes")
install.packages("yaml")
install.packages("readr")
install.packages("tidypredict")
install.packages("broom")
library(data.table)
library(dplyr)
library(lubridate)
#load data
userdata_1k <- fread("../../data/userdata_1k.csv")
setwd("C:/Users/julie/Documents/thesis/github/src/data_prep")
#load data
userdata_1k <- fread("../../data/userdata_1k.csv")
#remove columns
userdata_1k <- userdata_1k[-c(1)]
# timestamp to dates
userdata_1k$date <- as.Date(userdata_1k$timestamp)
# dates to total time timestamps
userdata_1k <- userdata_1k %>% group_by(userid) %>% mutate(total_days = max(date)-min(date))
# days numeric
userdata_1k$total_days_num <- as.numeric(userdata_1k$total_days, unit = "days")
# months numeric
userdata_1k$months <- time_length(userdata_1k$total_days, unit = "months")
# rearrange colums
userdata_1k <- userdata_1k[, c(1, 2, 7:10, 3:6)]
View(userdata_1k)
max(userdata_1k$total_days_num)
min(userdata_1k$total_days_num)
View(userdata_1k)
userdata_user_totaldays <- userdata_1k[, -c(1,3:5, 7:10)]
View(userdata_user_totaldays)
userdata_user_totaldays <- userdata_user_totaldays[!duplicated(userdata_user_totaldays), ]
library(ggplot2)
ggplot(userdata_user, aes(total_days_num)) + geom_bar()
ggplot(userdata_user_totaldays, aes(total_days_num)) + geom_bar()
ggplot(userdata_user_totaldays, aes(total_days_num)) + geom_area()
rlang::last_error()
ggplot(userdata_user_totaldays, aes(total_days_num)) + geom_area(stat = "bin")
ggplot(userdata_user_totaldays, aes(total_days_num)) + geom_density(kernel = "gaussian")
ggplot(userdata_user_totaldays, aes(total_days_num)) + geom_freqpoly()
ggplot(userdata_user_totaldays, aes(total_days_num)) + geom_histogram(binwidth = 100)
userdata_user_totaldays <- userdata_user_totaldays %>% filter(total_days_num <= 1541)
ggplot(userdata_user_totaldays, aes(total_days_num)) + geom_histogram(binwidth = 100)
ggplot(userdata_user_totaldays, aes(total_days_num)) + geom_histogram(binwidth = 10)
ggplot(userdata_user_totaldays, aes(total_days_num)) + geom_histogram(binwidth = 20)
ggplot(userdata_user_totaldays, aes(total_days_num)) + geom_histogram(binwidth = 30)
ggplot(userdata_user_totaldays, aes(total_days_num)) + geom_histogram(binwidth = 33)
ggplot(userdata_user_totaldays, aes(total_days_num)) + geom_histogram(binwidth = 40)
ggplot(userdata_user_totaldays, aes(total_days_num)) + geom_histogram(binwidth = 30)
