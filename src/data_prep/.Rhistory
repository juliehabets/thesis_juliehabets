# download it!
download.file(url, destfile = out_file, mode = "wb")
library(readr)
library(dplyr)
library(tidyr)
library(lubridate)
library(fixest)
library(broom)
library(ggplot2)
library(modelsummary)
paidsearch <- read_csv("data/paid_search.csv")
spec(paidsearch)
library(janitor)
paidsearch <-
paidsearch %>%
clean_names()
paidsearch <-
paidsearch %>%
mutate(revenue = revenue/1000)
paidsearch <-
paidsearch %>%
mutate(date  = as_date(date, format = '%d-%b-%y'))
paidsearch %>%
group_by(date) %>%
summarise(revenue = mean(revenue)) %>%
ggplot(aes(x = date,
y = revenue)
) +
geom_line() +
scale_x_date(date_labels = "%Y %b %d") +
theme_bw()
paidsearch <-
paidsearch %>%
mutate(calweek = week(date))
grp_avg <-
paidsearch %>%
group_by(search_stays_on, calweek) %>%
summarise(revenue = mean(revenue)) %>%
arrange(calweek, search_stays_on)
knitr::include_graphics('figs/ebay_experiment.png')
exp_start <- as_date("2015-05-22")
grp_avg %>%
ggplot(aes(x = calweek,
y = revenue,
color = factor(search_stays_on)
)
) +
geom_line() +
geom_vline(xintercept = week(exp_start)) +
ggtitle("Average Daily Revenue from Search Engine Marketing") +
xlab("Calendar Week") +
ylab("Revenue ('000s of USD)") +
theme_bw()
paidsearch <-
paidsearch %>%
mutate(treatment = case_when(
search_stays_on == 0 ~ 1,
TRUE ~ 0
)
) %>%
rename(after = treatment_period)
treat_table <-
paidsearch %>%
group_by(after, treatment) %>%
summarise(revenue = mean(revenue)) %>%
ungroup()
print(treat_table)
diff_no_treat <- abs(128.0709	- 131.5569)
diff_treat <- 104.9987	- 100.4183
did <- diff_no_treat - diff_treat
reg_did <- feols(revenue ~ after +
treatment +
after:treatment,
data = paidsearch)
tidy(reg_did, conf.int = TRUE)
reg_did_log <- feols(log(revenue) ~ after +
treatment +
after:treatment,
data = paidsearch)
tidy(reg_did_log, conf.int = TRUE)
#SE were se = "iid", but if there are clusters, se = "cluster". If vcov = "iid", then the standard-errors are based on the assumption that the errors are all independent and generated with the same law (in particular, same variance). If vcov = "hetero", this corresponds to the classic hereoskedasticity-robust standard-errors (White correction), where it is assumed that the errors are independent but the variance of their generative law may vary. If vcov = "cluster", then arbitrary correlation of the errors within clusters is accounted for. Same for vcov = "twoway": arbitrary correlation within each of the two clusters is accounted for.
reg_did_log_clust <- feols(log(revenue) ~ after +
treatment +
after:treatment,
cluster =  ~ {dma},
data = paidsearch)
tidy(reg_did_log_clust, conf.int = TRUE)
reg_did_log_fixed <- feols(log(revenue) ~ after +
treatment +
after:treatment
|
dma,
data = paidsearch)
tidy(reg_did_log_fixed, se='cluster', conf.int = TRUE)
mods <- list(
reg_did,
reg_did_log,
reg_did_log_clust,
reg_did_log_fixed)
msummary(mods,
coef_omit = "Interc",
gof_omit = "AIC|BIC|Log|Pseudo|F")
library(fixest)
coefplot(mods)
# Write your answer here
grp_avg %>%
filter(calweek <= week(exp_start)) %>%
ggplot(aes(x = calweek,
y = revenue,
color = factor(search_stays_on)
)
) +
geom_line() +
ggtitle("Average Daily Revenue from Search Engine Marketing",
subtitle = "Pre-treatment Period") +
xlab("Calendar Week") +
ylab("Revenue ('000s of USD)") +
theme_bw()
install.packages("spotifyr")
library(spotifyr)
install.packages("vagalumeR")
library(vagalumeR)
# vagalumeR
artist <-"belle-sebastian"
song <- songNames(artist)
View(song)
library(tidyverse)
glimpse(lyrics_data)
lyrics_data <- song %>%
pull(song.id) %>%
purrr::map(lyrics,
artist = artist,
type = "id",
key = key) %>%
purrr::map_df(data.frame) %>%
slice(-15) # There is a repeated lyric there!
lyrics_data <- song %>%
pull(song.id) %>%
purrr::map(lyrics,
artist = artist,
type = "id",
key = key) %>%
purrr::map_df(data.frame) %>%
slice(-15) # There is a repeated lyric there!
# vagalumeR
key <- 835426a514b5ad77b79de934a7b936df
# vagalumeR
key <- "835426a514b5ad77b79de934a7b936df"
lyrics_data <- song %>%
pull(song.id) %>%
purrr::map(lyrics,
artist = artist,
type = "id",
key = key) %>%
purrr::map_df(data.frame) %>%
slice(-15) # There is a repeated lyric there!
glimpse(lyrics_data)
install.packages("Rspotify")
library(Rspotify)
install.packages("httr")
install.packages("httr")
library(httr)
library(Rspotify)
# Rspotify
my_oauth <- spotifyOAuth()
# Rspotify
my_oauth <- spotifyOAuth(client_id = "b57bb630866045ee85b513376a7f8cc5", client_secret = "391b897e9e204c27aaa35d7d7ba91c52")
# Rspotify
my_oauth <- spotifyOAuth(app_id = "thesis", client_id = "b57bb630866045ee85b513376a7f8cc5", client_secret = "391b897e9e204c27aaa35d7d7ba91c52")
library(Rspotify)
library(vagalumeR)
library(tidyverse)
library(httr)
# Rspotify
SPOTIFY_ID <- "b57bb630866045ee85b513376a7f8cc5"
SECRET_KEY <- "391b897e9e204c27aaa35d7d7ba91c52"
response <- POST(
"https://accounts.spotify.com/api/token",
config = authenticate(user = Sys.getenv("SPOTIFY_ID"),
password = Sys.getenv("SECRET_KEY")),
body = list(grant_type = "client_credentials"),
encode = "form"
)
#extract content of response
token <-  content(response)
# Paste the token_type with the access_token
# needs it when making the authorization
bearer.token <- paste(token$token_type, token$access_token)
track.id <- "5u6y4u5EgDv0peILf60H5t"
track.response <- GET(paste0("https://api.spotify.com/v1/audio-features/",track.id),
config = add_headers(Authorization = bearer.token)
)
View(track.response)
View(track.response)
library(dplyr)
# Paste the token_type with the access_token
# needs it when making the authorization
bearer.token <- paste(token$token_type, token$access_token)
track.response <- GET(paste0("https://api.spotify.com/v1/audio-features/",track.id),
config = add_headers(Authorization = bearer.token)
)
View(track.response)
track <- as_tibble(content( track.response ))
track.features <- track %>% select(c(1:11, 17, 18))
View(track)
View(response)
my_oauth <- spotifyOAuth(app_id = "thesis", client_id = "b57bb630866045ee85b513376a7f8cc5", client_secret = "391b897e9e204c27aaa35d7d7ba91c52")
)
my_oauth <- spotifyOAuth(app_id = "thesis", client_id = "b57bb630866045ee85b513376a7f8cc5", client_secret = "4db6865daf1f451fb3bc73b577e293b2")
my_oauth <- spotifyOAuth(app_id = "thesis", client_id = "b57bb630866045ee85b513376a7f8cc5", client_secret = "4db6865daf1f451fb3bc73b577e293b2")
my_oauth <- spotifyOAuth(app_id = "thesis", client_id = "b57bb630866045ee85b513376a7f8cc5", client_secret = "4db6865daf1f451fb3bc73b577e293b2")
my_oauth <- spotifyOAuth(app_id = "thesis", client_id = "b57bb630866045ee85b513376a7f8cc5", client_secret = "4db6865daf1f451fb3bc73b577e293b2")
install.packages("installr")
?installr
installing/loading the package: if(!require(installr)) { install.packages("installr"); require(installr)} #load / install+load installr   updateR(F, T, T, F, T, F, T) # install, move, update.package, quit R.
if(!require(installr)) { install.packages("installr"); require(installr)} #load / install+load installr   updateR(F, T, T, F, T, F, T) # install, move, update.package, quit R.
library(installr)
installing/loading the package: if(!require(installr)) { install.packages("installr"); require(installr)} #load / install+load installr   updateR(F, T, T, F, T, F, T) # install, move, update.package, quit R.
iif(!require(installr)) { install.packages("installr"); require(installr)} #load / install+load installr   updateR(F, T, T, F, T, F, T) # install, move, update.package, quit R.
if(!require(installr)) { install.packages("installr"); require(installr)} #load / install+load installr   updateR(F, T, T, F, T, F, T) # install, move, update.package, quit R.
if(!require(installr)) {
install.packages("installr"); require(installr)}
updateR()
updateR()
library(rtweet)
tweets <-
search_tweets(
"Spotify" + "Gender",
n = 400)
tweets <-
search_tweets(
c("Spotify", "Gender"),
n = 400)
tweets <-
search_tweets(
c("Spotify AND Gender"),
n = 400)
View(tweets)
tweets <-
search_tweets(
c("Spotify AND Gender"),
n = 400,
lang = 'en')
View(tweets)
tweets <-
search_tweets(
c("Spotify AND LGBTQ"),
n = 400,
lang = 'en')
View(tweets)
tweets <-
search_tweets(
"Spotify AND LGBTQ",
n = 400,
lang = 'en')
View(tweets)
tweets <-
search_tweets(
"Spotify AND LGBTQ",
n = 400,
lang = 'en',
include_rts = FALSE)
View(tweets)
tweets <-
search_tweets(
"Spotify AND Gender bias",
n = 400,
lang = 'en',
include_rts = FALSE)
tweets <-
search_tweets(
"Spotify AND genderbias",
n = 400,
lang = 'en',
include_rts = FALSE)
tweets <-
search_tweets(
"Spotify AND Bias",
n = 400,
lang = 'en',
include_rts = FALSE)
View(tweets)
tweets <-
search_tweets(
"Spotify AND gender AND bias",
n = 400,
lang = 'en',
include_rts = FALSE)
tweets <-
search_tweets(
"Spotify AND #blackhistorymonth",
n = 400,
lang = 'en',
include_rts = FALSE)
tweets <-
search_tweets(
"Spotify AND LGBTQ",
n = 400,
lang = 'en',
include_rts = FALSE)
View(tweets)
deezer <- search_tweets(
"Deezer",
n = 50,
lan = 'en'
)
library(rtweet)
deezer <- search_tweets(
"Deezer",
n = 50,
lan = 'en'
)
View(deezer)
?search_tweets
deezer <- search_tweets(
"Deezer",
n = 50,
lang = 'en'
)
View(deezer)
deezer <- search_tweets(
"#Deezer",
n = 50,
lang = 'en'
)
View(deezer)
library(readr)
install.packages("readr")
install.packages("readr")
library(installr)
install.packages("installr")
library(installr)
updateR()
library(readr)
install.packages("readr")
library(dplyr)
install.packages("dplyr")
install.packages("tidyverse")
install.packages("tidyverse")
# Load packages
library(tidyverse)
#Create data folder
dir.create("../../data")
# Input
urls_calender = c("http://data.insideairbnb.com/united-states/co/denver/2022-09-26/data/calendar.csv.gz",
"http://data.insideairbnb.com/ireland/leinster/dublin/2022-09-11/data/calendar.csv.gz",
"http://data.insideairbnb.com/united-kingdom/england/london/2022-09-10/data/calendar.csv.gz",
"http://data.insideairbnb.com/united-states/ca/los-angeles/2022-09-09/data/calendar.csv.gz",
"http://data.insideairbnb.com/italy/lombardy/milan/2022-09-14/data/calendar.csv.gz",
"http://data.insideairbnb.com/germany/bv/munich/2022-06-21/data/calendar.csv.gz",
"http://data.insideairbnb.com/united-states/ny/new-york-city/2022-09-07/data/calendar.csv.gz",
"http://data.insideairbnb.com/france/ile-de-france/paris/2022-06-06/data/calendar.csv.gz",
"http://data.insideairbnb.com/united-states/or/portland/2022-09-16/data/calendar.csv.gz",
"http://data.insideairbnb.com/united-states/ca/san-francisco/2022-09-07/data/calendar.csv.gz")
urls_listing = c("http://data.insideairbnb.com/united-states/co/denver/2022-09-26/data/listings.csv.gz",
"http://data.insideairbnb.com/ireland/leinster/dublin/2022-09-11/data/listings.csv.gz",
"http://data.insideairbnb.com/united-kingdom/england/london/2022-09-10/data/listings.csv.gz",
"http://data.insideairbnb.com/united-states/ca/los-angeles/2022-09-09/data/listings.csv.gz",
"http://data.insideairbnb.com/italy/lombardy/milan/2022-09-14/data/listings.csv.gz",
"http://data.insideairbnb.com/germany/bv/munich/2022-06-21/data/listings.csv.gz",
"http://data.insideairbnb.com/united-states/ny/new-york-city/2022-09-07/data/listings.csv.gz",
"http://data.insideairbnb.com/france/ile-de-france/paris/2022-06-06/data/listings.csv.gz",
"http://data.insideairbnb.com/united-states/or/portland/2022-09-16/data/listings.csv.gz",
"http://data.insideairbnb.com/united-states/ca/san-francisco/2022-09-07/data/listings.csv.gz")
install.packages("readr")
install.packages("readr")
install.packages("data.table")
install.packages("shiny")
install.packages("shinyWidgets")
install.packages("bslib")
install.packages("shinythemes")
install.packages("yaml")
install.packages("readr")
install.packages("tidypredict")
install.packages("broom")
setwd("C:/Users/julie/Documents/thesis/github/src/data_prep")
library(data.table)
library(dplyr)
library(stringr)
# load dataset
total_label <- fread("../../gen/temp/users_1month_complete.csv")
# clean
total_label <- total_label[-1, -1]
names(total_label)[c(1,2,3,4,5,6,7)] <- c("userid", "track_name", "artist_MBID", "artist", "track_MBID", "gender", "label")
# remove digits
total_label$label <- str_replace_all(total_label$label, "[:digit:]", "")
# remove parentheses () that were around the digits
total_label$label <- str_replace_all(total_label$label, "\\(\\)", "")
# add spaces around |
total_label$label <- str_replace_all(total_label$label, "\\|", " \\| ")
# remove leading and trailing spaces
total_label$label <- str_trim(total_label$label)
# remove double spaces
total_label$label <- str_squish(total_label$label)
View(total_label)
sum(is.na(total_label$label))
35755/620094
# write to csv
write.csv(total_label, "../../gen/temp/total_label_clean.csv")
# write to csv
write.csv(total_label, "../../gen/temp/users_1month_complete_clean.csv")
library(musicMetadata)
library(tidyr)
library(stringr)
# load dataset
total_label <- fread("../../gen/temp/users_1month_complete_clean.csv")
# clean
total_label <- total_label[-1, -1]
names(total_label)[c(1,2,3,4,5,6,7)] <- c("userid", "track_name", "artist_MBID", "artist", "track_MBID", "gender", "label")
# classify
labels <- unique(total_label$label)
classified_labels <- data.frame(label=labels, parent_label = classify_labels(labels, concatenate = T))
total_label <- full_join(total_label, classified_labels, by = "label")
# reduce the number of labels per song
total_label_red <- total_label %>% group_by(artist, track_name) %>% count(label)
View(total_label_red)
total_label_red <- total_label_red %>% group_by(artist, track_name) %>% mutate(max_n = max(n))
# keeping only most popular label
total_label_red <- total_label_red %>% group_by(artist, track_name) %>% filter(n == max_n)
View(total_label_red)
# reduce the number of labels per song
total_label_red <- total_label %>% group_by(artist) %>% count(label)
total_label_red <- total_label_red %>% group_by(artist) %>% mutate(max_n = max(n))
View(total_label_red)
View(classified_labels)
View(total_label_red)
View(total_label)
# keeping only most popular label
total_label_red <- total_label_red %>% group_by(artist) %>% filter(n == max_n)
# write to csv
write.csv(total_label, "../../gen/temp/label_classification.csv")
write.csv(classified_labels, "../../gen/temp/classified_labels.csv")
# try fixing
try <- total_label %>% filter(artist == "Lady Gaga")
# try fixing
try <- total_label %>% filter(artist == "lady gaga")
#try$track_name <-str_replace(try$track_name, " \\s*\\([^\\)]+\\)", "")
#try$track_name <-str_replace(try$track_name, " \\s*\\([^\\)]+\\)", "")
try <- try[!duplicated(try), ]
View(try)
try <- try %>% count(parent_label)
View(try)
try$parent_label[try$parent_label == ''] <- "indie"
try <- try %>% pivot_wider(names_from = "parent_label", values_from = "n")
try <- try %>% mutate(across(everything(), .fns = ~replace_na(.,0)))
try <- try %>% mutate(total_major = sum(`warner,sony` , `warner,universal`, `universal,sony`, warner, sony, universal))
#try <- try %>% mutate(across(everything(), .fns = ~replace_na(.,0)))
#try <- try %>% mutate(total_major = sum(`warner,sony` , `warner,universal`, `universal,sony`, warner, sony, universal))
#try <- try[, -c(3:8)]
try <- try %>% mutate(ratio = total_major/(indie+total_major))
# try fixing
try <- total_label %>% filter(artist == "lady gaga")
#try$track_name <-str_replace(try$track_name, " \\s*\\([^\\)]+\\)", "")
#try$track_name <-str_replace(try$track_name, " \\s*\\([^\\)]+\\)", "")
try <- try[!duplicated(try), ]
try <- try %>% count(parent_label)
try$parent_label[try$parent_label == ''] <- "indie"
try$parent_label[try$parent_label == 'universal'] <- "major"
try <- try %>% pivot_wider(names_from = "parent_label", values_from = "n")
#try <- try %>% mutate(across(everything(), .fns = ~replace_na(.,0)))
#try <- try %>% mutate(total_major = sum(`warner,sony` , `warner,universal`, `universal,sony`, warner, sony, universal))
#try <- try[, -c(3:8)]
try <- try %>% mutate(ratio = major/(indie+major))
# try total label
total_try <- total_label
total_try$parent_label[total_try$parent_label == ''] <- "indie"
View(total_try)
total_try$parent_label[!(total_try$parent_label == '')] <- "major"
# try total label
total_try <- total_label
?classify_laebls
?classify_labels
# classify
labels <- unique(!is.na(total_label$label))
# classify
labels <- (!is.na(total_label$label)
# classify
labels <- !is.na(total_label$label
# classify
labels <- !(is.na(total_label$label)
# load dataset
total_label <- fread("../../gen/temp/users_1month_complete_clean.csv")
# load dataset
total_label <- fread("../../gen/temp/users_1month_complete_clean.csv")
# clean
total_label <- total_label[-1, -1]
names(total_label)[c(1,2,3,4,5,6,7)] <- c("userid", "track_name", "artist_MBID", "artist", "track_MBID", "gender", "label")
# classify
labels <- !(is.na(total_label$label)
# classify
labels <- total_label %>% filter(!(is.na($label))
# classify
labels <- total_label %>% filter(!(is.na($label)))
# classify
labels <- total_label %>% filter(!(is.na(label)))
View(labels)
sum(is.na(labels$label))
labels <- unique(labels$label)
length(unique(labels$label))
# classify
labels <- total_label %>% filter(!(is.na(label)))
length(unique(labels$label))\
length(unique(labels$label))
labels <- unique(labels$label)
# classify labels
classified_labels <- data.frame(label=labels, parent_label = classify_labels(labels, concatenate = T))
View(classified_labels)
total_label <- full_join(total_label, classified_labels, by = "label")
View(total_label)
# write to csv
write.csv(total_label, "../../gen/temp/label_classification.csv")
write.csv(classified_labels, "../../gen/temp/classified_labels.csv")
