reg_did_log_clust,
reg_did_log_fixed)
summary(mods,
coef_omit = "Interc",
gof_omit = "AIC|BIC|Log|Pseudo|F")
mods <- list(
reg_did,
reg_did_log,
reg_did_log_clust,
reg_did_log_fixed)
msummary(mods,
coef_omit = "Interc",
gof_omit = "AIC|BIC|Log|Pseudo|F")
library(arm)
install.packages("arm")
library(arm)
library(arm)
coefplot(mods)
library(arm)
coefplot(reg_did, reg_did_log, reg_did_log_clust, reg_did_log_fixed)
library(fixest)
coefplot(reg_did, reg_did_log, reg_did_log_clust, reg_did_log_fixed)
coefplot(reg_did)
?coefplot
library(fixest)
coefplot(mods)
url <- "https://raw.githubusercontent.com/TaddyLab/BDS/master/examples/paidsearch.csv"
# where to save data
out_file <- "data/paid_search.csv"
# download it!
download.file(url, destfile = out_file, mode = "wb")
library(readr)
library(dplyr)
library(tidyr)
library(lubridate)
library(fixest)
library(broom)
library(ggplot2)
library(modelsummary)
paidsearch <- read_csv("data/paid_search.csv")
spec(paidsearch)
library(janitor)
paidsearch <-
paidsearch %>%
clean_names()
paidsearch <-
paidsearch %>%
mutate(revenue = revenue/1000)
paidsearch <-
paidsearch %>%
mutate(date  = as_date(date, format = '%d-%b-%y'))
paidsearch %>%
group_by(date) %>%
summarise(revenue = mean(revenue)) %>%
ggplot(aes(x = date,
y = revenue)
) +
geom_line() +
scale_x_date(date_labels = "%Y %b %d") +
theme_bw()
paidsearch <-
paidsearch %>%
mutate(calweek = week(date))
grp_avg <-
paidsearch %>%
group_by(search_stays_on, calweek) %>%
summarise(revenue = mean(revenue)) %>%
arrange(calweek, search_stays_on)
knitr::include_graphics('figs/ebay_experiment.png')
exp_start <- as_date("2015-05-22")
grp_avg %>%
ggplot(aes(x = calweek,
y = revenue,
color = factor(search_stays_on)
)
) +
geom_line() +
geom_vline(xintercept = week(exp_start)) +
ggtitle("Average Daily Revenue from Search Engine Marketing") +
xlab("Calendar Week") +
ylab("Revenue ('000s of USD)") +
theme_bw()
paidsearch <-
paidsearch %>%
mutate(treatment = case_when(
search_stays_on == 0 ~ 1,
TRUE ~ 0
)
) %>%
rename(after = treatment_period)
treat_table <-
paidsearch %>%
group_by(after, treatment) %>%
summarise(revenue = mean(revenue)) %>%
ungroup()
print(treat_table)
diff_no_treat <- abs(128.0709	- 131.5569)
diff_treat <- 104.9987	- 100.4183
did <- diff_no_treat - diff_treat
reg_did <- feols(revenue ~ after +
treatment +
after:treatment,
data = paidsearch)
tidy(reg_did, conf.int = TRUE)
reg_did_log <- feols(log(revenue) ~ after +
treatment +
after:treatment,
data = paidsearch)
tidy(reg_did_log, conf.int = TRUE)
#SE were se = "iid", but if there are clusters, se = "cluster". If vcov = "iid", then the standard-errors are based on the assumption that the errors are all independent and generated with the same law (in particular, same variance). If vcov = "hetero", this corresponds to the classic hereoskedasticity-robust standard-errors (White correction), where it is assumed that the errors are independent but the variance of their generative law may vary. If vcov = "cluster", then arbitrary correlation of the errors within clusters is accounted for. Same for vcov = "twoway": arbitrary correlation within each of the two clusters is accounted for.
reg_did_log_clust <- feols(log(revenue) ~ after +
treatment +
after:treatment,
cluster =  ~ {dma},
data = paidsearch)
tidy(reg_did_log_clust, conf.int = TRUE)
reg_did_log_fixed <- feols(log(revenue) ~ after +
treatment +
after:treatment
|
dma,
data = paidsearch)
tidy(reg_did_log_fixed, se='cluster', conf.int = TRUE)
mods <- list(
reg_did,
reg_did_log,
reg_did_log_clust,
reg_did_log_fixed)
msummary(mods,
coef_omit = "Interc",
gof_omit = "AIC|BIC|Log|Pseudo|F")
library(fixest)
coefplot(mods)
# Write your answer here
grp_avg %>%
filter(calweek <= week(exp_start)) %>%
ggplot(aes(x = calweek,
y = revenue,
color = factor(search_stays_on)
)
) +
geom_line() +
ggtitle("Average Daily Revenue from Search Engine Marketing",
subtitle = "Pre-treatment Period") +
xlab("Calendar Week") +
ylab("Revenue ('000s of USD)") +
theme_bw()
install.packages("spotifyr")
library(spotifyr)
install.packages("vagalumeR")
library(vagalumeR)
# vagalumeR
artist <-"belle-sebastian"
song <- songNames(artist)
View(song)
library(tidyverse)
glimpse(lyrics_data)
lyrics_data <- song %>%
pull(song.id) %>%
purrr::map(lyrics,
artist = artist,
type = "id",
key = key) %>%
purrr::map_df(data.frame) %>%
slice(-15) # There is a repeated lyric there!
lyrics_data <- song %>%
pull(song.id) %>%
purrr::map(lyrics,
artist = artist,
type = "id",
key = key) %>%
purrr::map_df(data.frame) %>%
slice(-15) # There is a repeated lyric there!
# vagalumeR
key <- 835426a514b5ad77b79de934a7b936df
# vagalumeR
key <- "835426a514b5ad77b79de934a7b936df"
lyrics_data <- song %>%
pull(song.id) %>%
purrr::map(lyrics,
artist = artist,
type = "id",
key = key) %>%
purrr::map_df(data.frame) %>%
slice(-15) # There is a repeated lyric there!
glimpse(lyrics_data)
install.packages("Rspotify")
library(Rspotify)
install.packages("httr")
install.packages("httr")
library(httr)
library(Rspotify)
# Rspotify
my_oauth <- spotifyOAuth()
# Rspotify
my_oauth <- spotifyOAuth(client_id = "b57bb630866045ee85b513376a7f8cc5", client_secret = "391b897e9e204c27aaa35d7d7ba91c52")
# Rspotify
my_oauth <- spotifyOAuth(app_id = "thesis", client_id = "b57bb630866045ee85b513376a7f8cc5", client_secret = "391b897e9e204c27aaa35d7d7ba91c52")
library(Rspotify)
library(vagalumeR)
library(tidyverse)
library(httr)
# Rspotify
SPOTIFY_ID <- "b57bb630866045ee85b513376a7f8cc5"
SECRET_KEY <- "391b897e9e204c27aaa35d7d7ba91c52"
response <- POST(
"https://accounts.spotify.com/api/token",
config = authenticate(user = Sys.getenv("SPOTIFY_ID"),
password = Sys.getenv("SECRET_KEY")),
body = list(grant_type = "client_credentials"),
encode = "form"
)
#extract content of response
token <-  content(response)
# Paste the token_type with the access_token
# needs it when making the authorization
bearer.token <- paste(token$token_type, token$access_token)
track.id <- "5u6y4u5EgDv0peILf60H5t"
track.response <- GET(paste0("https://api.spotify.com/v1/audio-features/",track.id),
config = add_headers(Authorization = bearer.token)
)
View(track.response)
View(track.response)
library(dplyr)
# Paste the token_type with the access_token
# needs it when making the authorization
bearer.token <- paste(token$token_type, token$access_token)
track.response <- GET(paste0("https://api.spotify.com/v1/audio-features/",track.id),
config = add_headers(Authorization = bearer.token)
)
View(track.response)
track <- as_tibble(content( track.response ))
track.features <- track %>% select(c(1:11, 17, 18))
View(track)
View(response)
my_oauth <- spotifyOAuth(app_id = "thesis", client_id = "b57bb630866045ee85b513376a7f8cc5", client_secret = "391b897e9e204c27aaa35d7d7ba91c52")
)
my_oauth <- spotifyOAuth(app_id = "thesis", client_id = "b57bb630866045ee85b513376a7f8cc5", client_secret = "4db6865daf1f451fb3bc73b577e293b2")
my_oauth <- spotifyOAuth(app_id = "thesis", client_id = "b57bb630866045ee85b513376a7f8cc5", client_secret = "4db6865daf1f451fb3bc73b577e293b2")
my_oauth <- spotifyOAuth(app_id = "thesis", client_id = "b57bb630866045ee85b513376a7f8cc5", client_secret = "4db6865daf1f451fb3bc73b577e293b2")
my_oauth <- spotifyOAuth(app_id = "thesis", client_id = "b57bb630866045ee85b513376a7f8cc5", client_secret = "4db6865daf1f451fb3bc73b577e293b2")
install.packages("installr")
?installr
installing/loading the package: if(!require(installr)) { install.packages("installr"); require(installr)} #load / install+load installr   updateR(F, T, T, F, T, F, T) # install, move, update.package, quit R.
if(!require(installr)) { install.packages("installr"); require(installr)} #load / install+load installr   updateR(F, T, T, F, T, F, T) # install, move, update.package, quit R.
library(installr)
installing/loading the package: if(!require(installr)) { install.packages("installr"); require(installr)} #load / install+load installr   updateR(F, T, T, F, T, F, T) # install, move, update.package, quit R.
iif(!require(installr)) { install.packages("installr"); require(installr)} #load / install+load installr   updateR(F, T, T, F, T, F, T) # install, move, update.package, quit R.
if(!require(installr)) { install.packages("installr"); require(installr)} #load / install+load installr   updateR(F, T, T, F, T, F, T) # install, move, update.package, quit R.
if(!require(installr)) {
install.packages("installr"); require(installr)}
updateR()
updateR()
library(rtweet)
tweets <-
search_tweets(
"Spotify" + "Gender",
n = 400)
tweets <-
search_tweets(
c("Spotify", "Gender"),
n = 400)
tweets <-
search_tweets(
c("Spotify AND Gender"),
n = 400)
View(tweets)
tweets <-
search_tweets(
c("Spotify AND Gender"),
n = 400,
lang = 'en')
View(tweets)
tweets <-
search_tweets(
c("Spotify AND LGBTQ"),
n = 400,
lang = 'en')
View(tweets)
tweets <-
search_tweets(
"Spotify AND LGBTQ",
n = 400,
lang = 'en')
View(tweets)
tweets <-
search_tweets(
"Spotify AND LGBTQ",
n = 400,
lang = 'en',
include_rts = FALSE)
View(tweets)
tweets <-
search_tweets(
"Spotify AND Gender bias",
n = 400,
lang = 'en',
include_rts = FALSE)
tweets <-
search_tweets(
"Spotify AND genderbias",
n = 400,
lang = 'en',
include_rts = FALSE)
tweets <-
search_tweets(
"Spotify AND Bias",
n = 400,
lang = 'en',
include_rts = FALSE)
View(tweets)
tweets <-
search_tweets(
"Spotify AND gender AND bias",
n = 400,
lang = 'en',
include_rts = FALSE)
tweets <-
search_tweets(
"Spotify AND #blackhistorymonth",
n = 400,
lang = 'en',
include_rts = FALSE)
tweets <-
search_tweets(
"Spotify AND LGBTQ",
n = 400,
lang = 'en',
include_rts = FALSE)
View(tweets)
deezer <- search_tweets(
"Deezer",
n = 50,
lan = 'en'
)
library(rtweet)
deezer <- search_tweets(
"Deezer",
n = 50,
lan = 'en'
)
View(deezer)
?search_tweets
deezer <- search_tweets(
"Deezer",
n = 50,
lang = 'en'
)
View(deezer)
deezer <- search_tweets(
"#Deezer",
n = 50,
lang = 'en'
)
View(deezer)
library(readr)
install.packages("readr")
install.packages("readr")
library(installr)
install.packages("installr")
library(installr)
updateR()
library(readr)
install.packages("readr")
library(dplyr)
install.packages("dplyr")
install.packages("tidyverse")
install.packages("tidyverse")
# Load packages
library(tidyverse)
#Create data folder
dir.create("../../data")
# Input
urls_calender = c("http://data.insideairbnb.com/united-states/co/denver/2022-09-26/data/calendar.csv.gz",
"http://data.insideairbnb.com/ireland/leinster/dublin/2022-09-11/data/calendar.csv.gz",
"http://data.insideairbnb.com/united-kingdom/england/london/2022-09-10/data/calendar.csv.gz",
"http://data.insideairbnb.com/united-states/ca/los-angeles/2022-09-09/data/calendar.csv.gz",
"http://data.insideairbnb.com/italy/lombardy/milan/2022-09-14/data/calendar.csv.gz",
"http://data.insideairbnb.com/germany/bv/munich/2022-06-21/data/calendar.csv.gz",
"http://data.insideairbnb.com/united-states/ny/new-york-city/2022-09-07/data/calendar.csv.gz",
"http://data.insideairbnb.com/france/ile-de-france/paris/2022-06-06/data/calendar.csv.gz",
"http://data.insideairbnb.com/united-states/or/portland/2022-09-16/data/calendar.csv.gz",
"http://data.insideairbnb.com/united-states/ca/san-francisco/2022-09-07/data/calendar.csv.gz")
urls_listing = c("http://data.insideairbnb.com/united-states/co/denver/2022-09-26/data/listings.csv.gz",
"http://data.insideairbnb.com/ireland/leinster/dublin/2022-09-11/data/listings.csv.gz",
"http://data.insideairbnb.com/united-kingdom/england/london/2022-09-10/data/listings.csv.gz",
"http://data.insideairbnb.com/united-states/ca/los-angeles/2022-09-09/data/listings.csv.gz",
"http://data.insideairbnb.com/italy/lombardy/milan/2022-09-14/data/listings.csv.gz",
"http://data.insideairbnb.com/germany/bv/munich/2022-06-21/data/listings.csv.gz",
"http://data.insideairbnb.com/united-states/ny/new-york-city/2022-09-07/data/listings.csv.gz",
"http://data.insideairbnb.com/france/ile-de-france/paris/2022-06-06/data/listings.csv.gz",
"http://data.insideairbnb.com/united-states/or/portland/2022-09-16/data/listings.csv.gz",
"http://data.insideairbnb.com/united-states/ca/san-francisco/2022-09-07/data/listings.csv.gz")
install.packages("readr")
install.packages("readr")
install.packages("data.table")
install.packages("shiny")
install.packages("shinyWidgets")
install.packages("bslib")
install.packages("shinythemes")
install.packages("yaml")
install.packages("readr")
install.packages("tidypredict")
install.packages("broom")
setwd("C:/Users/julie/Documents/thesis/github/src/data_prep")
library(data.table)
library(dplyr)
# load data
match_tracks_join_full <- fread("../../gen/temp/match_tracks_join_full.csv")
users_1month <- fread("../../gen/temp/users_1month.csv")
# clean datasets
match_tracks_join_full <- match_tracks_join_full[, -1]
names(match_tracks_join_full)[c(3)] <- c("track_name")
users_1month <- users_1month[, -c(1, 3:8, 10)]
# no duplicate rows
users_1month <- users_1month[!duplicated(users_1month), ]
users_tracks <- full_join(users_1month, match_tracks_join_full, by = "track_name")
# clean
users_tracks <- users_tracks[, -c(1,4:6)]
names(users_tracks)[c(1,3)] <- c("artist", "label")
users_tracks <- users_tracks[!duplicated(users_tracks), ]
# check NAs
na <- users_tracks %>% filter(is.na(label))
no_na <- users_tracks %>% filter(!(is.na(label)))
na_check <- na %>% filter(artist %in% no_na$artist)
# impute NAs
label_artist_count <- no_na %>% group_by(artist) %>% count(label)
label_artist_count <- label_artist_count %>% group_by(artist) %>% mutate(max_n = max(n))
# keeping only most popular label
label_artist_count <- label_artist_count %>% group_by(artist) %>% filter(n == max_n)
# keeping only 1 label per artist in case when the max counts are the same
label_artist_count <- label_artist_count %>% group_by(artist) %>% slice(n=1)
label_artist_count <- label_artist_count[, 1:2]
# impute NAs
na_check <- merge(na_check, label_artist_count, by = "artist")
na_check <- na_check[, -3]
names(na_check)[c(3)] <- c( "label")
View(na_check)
# rejoining
users_tracks <- rbind(no_na, na, na_check)
users_tracks <- users_tracks[!duplicated(users_tracks), ]
View(users_tracks)
sum(is.na(users_tracks$label))
match_artists <- fread("../../gen/temp/match_artists.csv")
match_artists <- match_artists[-1, -1]
names(match_artists)[c(1,2)] <- c("artist","label")
users_artists <- full_join(users_1month, match_artists, by = "artist")
# clean
users_artists <- users_artists[, -c(1,4)]
users_artists <- users_artists[!duplicated(users_artists), ]
# check NAs
users_artists_na <- users_artists %>% filter(is.na(label))
users_artists_nona <- users_artists %>% filter(!is.na(label))
na_check <- users_artists_na %>% filter(!(artist %in% users_artists_nona$artist))
# none of the artist NA's are in the no NA subset
rm(na_check)
# in case of multiple labels per song
users_artists_nona <- users_artists_nona %>% group_by(artist, track_name) %>% count(label)
users_artists_nona <- users_artists_nona %>% group_by(artist, track_name) %>% mutate(max_n = max(n))
# keeping only most popular label
users_artists_nona <- users_artists_nona %>% group_by(artist, track_name) %>% filter(n == max_n)
# keeping only 1 label per artist in case when the max counts are the same
users_artists_nona <- users_artists_nona %>% group_by(artist, track_name) %>% slice(n=1)
users_artists_nona <- users_artists_nona[, 1:3]
# bind datasets together
users_artists <- rbind(users_artists_nona, users_artists_na)
users_artists <- users_artists[!duplicated(users_artists), ]
# Add datasets together
total_label <- users_tracks
total_label$label[is.na(total_label$label)] <- users_artists$label[match(total_label$artist,users_artists$artist)][which(is.na(total_label$label))]
sum(is.na(total_label$label))
sum(is.na(user_tracks$label))
sum(is.na(users_tracks$label))
View(users_artists)
View(users_artists)
total_label$label[is.na(total_label$label)] <- users_artists$label[match(total_label$track_name,users_artists$track_name)][which(is.na(total_label$label))]
sum(is.na(total_label$label))
# clean
total_label <- total_label[!duplicated(total_label), ]
# checking NAs
na <- total_label %>% filter(is.na(label))
na <- na %>% filter(!(artist %in% users_artists_nona$artist))
#write to csv
write.csv(total_label, "../../gen/temp/total_label.csv")
# checking NAs
na <- total_label %>% filter(is.na(label))
na <- na %>% filter(!(artist %in% users_artists_nona$artist))
# checking NAs
na <- total_label %>% filter(is.na(label))
na <- na %>% filter(!(artist %in% users_artists_nona$artist))
na <- na %>% filter(!(artist %in% no_na$artist))
# checking NAs
na <- total_label %>% filter(is.na(label))
na <- na %>% filter(!(artist %in% no_na$artist))
# checking NAs
na <- total_label %>% filter(is.na(label))
View(no_na)
total_label$label[is.na(total_label$label)] <- no_na$label[match(total_label$track_name,no_na$track_name)][which(is.na(total_label$label))]
total_label$label[is.na(total_label$label)] <- no_na$label[match(total_label$artist,no_na$artist)][which(is.na(total_label$label))]
View(users_artists_nona)
total_label$label[is.na(total_label$label)] <- users_artists_nona$label[match(total_label$track_name,users_artists_nona$track_name)][which(is.na(total_label$label))]
total_label$label[is.na(total_label$label)] <- users_artists_nona$label[match(total_label$artist,users_artists_nona$users_artists_nona)][which(is.na(total_label$label))]
total_label$label[is.na(total_label$label)] <- users_artists_nona$label[match(total_label$artist,users_artists_nona$artist)][which(is.na(total_label$label))]
# clean
total_label <- total_label[!duplicated(total_label), ]
# checking NAs
na <- total_label %>% filter(is.na(label))
View(na)
length(unique(na$artist))
length(unique(na$track_name))
#write to csv
write.csv(total_label, "../../gen/temp/total_label.csv")
